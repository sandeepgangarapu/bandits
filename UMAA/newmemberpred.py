# -*- coding: utf-8 -*-
"""NewMemberPred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KU_LO066e1C-udGIDN3ksS4fogtctQ80
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# %matplotlib inline
# import necessary libraries and specify that graphs should be plotted inline. 
# from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import classification_report,auc, accuracy_score, confusion_matrix, roc_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction import DictVectorizer
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import pydotplus
import seaborn as sns
from sklearn.tree import export_graphviz
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE

# Loading files

from google.colab import drive
drive.mount('/content/drive/')

# load the data
data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/UMAA/data_for_model.csv')

data.head(5)

data.target.value_counts()

"""## Model"""

#  filling null values with popular occurance of that **variable**
data = data.fillna(data['IS_CURRENT_TC_EMPLOYEE'].value_counts().index[0])

# one hot encoding of marital status

data = pd.get_dummies(data, columns=['MARITAL_STATUS'], prefix = ['MARITAL_STATUS'])
data = data.drop(['MARITAL_STATUS_O'], axis = 1)
data['MARITAL_STATUS_U'] = data['MARITAL_STATUS_U'].astype('category')
data['MARITAL_STATUS_M'] = data['MARITAL_STATUS_M'].astype('category')

col_names_object = ['GENDER', 'IN_TC_METRO_AREA', 'IS_CURRENT_TC_EMPLOYEE', 'ATHLETIC_INTEREST', 'TRAVEL_INTEREST', 'AFFINITY_NETWORK_INTEREST', 'WEB_TOPIC_OPT_INS']

for col in col_names_object:
  data[col] = data[col].astype('category')

data['target'] = data['target'].astype('category')

print(data.info())

y = data['target']
x = data.drop(['ID_DEMO','target'], axis = 1)



X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.33, random_state = 42, stratify = y)

"""### Random Forest"""

## Random Forest

# hyper parameters to tune
# n_estimators = [100,300,500]
# max_depth = [4,6,8]
# min_samples_split = [2,4]
# hyper = dict(n_estimators = n_estimators, max_depth = max_depth, 
#              min_samples_split = min_samples_split)
# rf = RandomizedSearchCV(RandomForestClassifier(),hyper,cv = 3)

# setup the model
rf = RandomForestClassifier(n_estimators= 100, max_depth = 8,min_samples_split=2)
# fit the model
rf.fit(X_train,y_train)
# predict the result
pred_rf_no = rf.predict(X_test)
pred_rf_no_all = rf.predict(x)

# Get the model performance
# the result will be printed out by running the below code
print(classification_report(y_test, pred_rf_no))

# Get all measurement
columns_name = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
accuracy = accuracy_score(y_test, pred_rf_no)
print('Accuracy of Decision Tree is {0}'.format(round(accuracy,4)))

# !pip install tpot

from tpot import TPOTClassifier

model = TPOTClassifier(generations=5, population_size=50, scoring='roc_auc', verbosity=2, random_state=1, n_jobs=-1)
model.fit(X_train,y_train)