---
title: "MAB Simulations"
author: "Sandeep Gangarapu"
output: html_document
---


```{r echo=FALSE, warning=FALSE}
suppressPackageStartupMessages(
  {
library(ggplot2)
library(dplyr)
library(tidyr)
library(directlabels)
library(gganimate)
library(cumstats)
  })
```

# Simulation set up

We have 10 arms which have a normal outcome distribution with different means and variances. The values of these true means and variances are given below.

Every time we pull an arm (make an allocation), we sample from the normal distribution of given by the mean and variance of that arm.

We see from the below true values that ARM-8 should the winning arm as it has the highest mean of 4.9.



```{r echo=TRUE}

true_means = c(0,1,2,3,4)

true_vars = c(1,1,1,1,1)

grp = c(0:(length(true_means)-1))
true_df <- data.frame(grp, true_means, true_vars)
true_df <- true_df %>% mutate(grp=factor(grp))

```

Time Horizon is the number of allocations we have available synonymous to number of experimental units in an experiment. 
In this simulation, we set time horizon to 2000 units.

We run this simulation for 20 different times using various seeds.



```{r echo=FALSE, cache=FALSE, warning=FALSE}
setwd("G:\\My Drive\\Research\\Bandits\\code\\bandits\\analysis\\output")


data <- read.csv("wise_mse_graph.csv")


seed_algs <- c("ab", "ucb", "thomp", "eps_greedy")
inf_algs <- c("ucb_inf_eps", "thomp_inf_eps", 'thomp_inf')
est_algs <- c("thomp_ipw", "thomp_aipw", "thomp_inf_eps_ipw", "thomp_inf_eps_aipw", "thomp_eval_aipw", "thomp_inf_eps_eval_aipw", "ucb_aipw", "ucb_ipw",  "ucb_inf_eps_aipw", "ucb_inf_eps_ipw", "ucb_eval_aipw", "ucb_inf_eps_eval_aipw" )
thomp_algs = c( "thomp", "thomp_inf_eps")
ucb_algs <- c("ucb_inf_eps", "ucb")
adv_algs <- c(thomp_algs, ucb_algs)


group_outcome <- data %>% filter(alg %in% c(seed_algs, inf_algs)) %>%
  select(alg, group, ite, outcome) %>%
  group_by(ite,alg) %>% mutate(x=row_number()) %>%
  ungroup()

regret_mse <- data %>% filter(alg %in% c(seed_algs, inf_algs)) %>%
  select(alg, regret, ite, mean_mse, var_mse) %>%
  group_by(ite,alg) %>% mutate(x=row_number()) %>%
  ungroup()

# prop_mse <- data %>% filter(alg %in% est_algs) %>% select(alg, ite, group, mse, mean_est) %>% 
#   group_by(ite,alg) %>% mutate(x=row_number()) %>% ungroup()

xlimit <- max(group_outcome$x) + 300
 

# Setting new WD so that results are saved in different folder
setwd("G:\\My Drive\\Research\\Bandits\\code\\bandits\\analysis\\results")


```



# Mean Squared error of mean estimates

At each time horizon we use sample mean to estimate mean of each arm and calculate error = est.mean-true.mean.

$MSE = \sum_{k} (error_k)^2$


```{r echo=FALSE, warning=FALSE}
# df_prop <- prop_mse %>% select(-c(mean_est, group))
df_mse <- regret_mse %>% select(-c(regret, var_mse)) %>% rename(mse = mean_mse)
# total_mse <- rbind(df_prop, df_mse) %>% group_by(x, alg) %>% summarise(mn_mse = mean(mse), se_mse = sd(mse)/sqrt(n()))
# 
# dt <- total_mse %>% filter(alg %in% seed_algs)
# 
# ggplot(df_mse,aes(x=x, y=mn_mse)) +
#   geom_line(aes(color=alg)) +
#   geom_ribbon(aes(ymin=mn_mse-(1.96*se_mse), ymax=mn_mse+(1.96*se_mse),
#                   group=alg), alpha=0.4,  fill="grey70") +
#   labs(title = "MSE of Mean") +  xlim(0,xlimit) +
#   geom_dl(aes(label=alg), method=list('last.points', cex=0.8)) +
#   theme_bw()

plot_mse <- ggplot(df_mse,aes(x=x, y=mse)) +
  geom_line(aes(color=alg)) +
  labs(title = "MSE of Mean") +  xlim(0,xlimit) +
  geom_dl(aes(label=alg), method=list('last.points', cex=0.8)) +
  theme_bw()

```


UCB and Thompson Sampling have higher MSE compared to AB or Epsilon Greedy. This means that the estimates of AB and Epsilon-Greedy are more accurate.


```{r echo=FALSE, warning=FALSE}

less_mse_algs = c("ab", "eps_greedy", "ucb_inf_eps", "thomp_inf_eps")
this_algs <- c('ucb', 'thomp', less_mse_algs)

dt <- total_mse %>% filter(alg %in% this_algs)


plot_mse <- ggplot(dt,aes(x=x, y=mn_mse)) +
  geom_line(aes(color=alg)) +
  geom_ribbon(aes(ymin=mn_mse-(1.96*se_mse), ymax=mn_mse+(1.96*se_mse),
                  group=alg), alpha=0.4,  fill="grey70") +
  labs(title = "MSE of Mean") +  xlim(0,xlimit) +
  geom_dl(aes(label=alg), method=list('last.points', cex=0.8)) +
  theme_bw()

plot_mse

```
The Inference based algorithms are performing much better than Bandit algorithms in terms if MSE and are comparable to traditional algorithms.

Difference between the above algorithms is clear during later allocations. So we limit the Y axis to see these differences.

```{r echo=FALSE, warning=FALSE}

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,2.3)

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,0.3)

```

AB, UCB_INF_EPS, THOMP_INF_EPS perform the best and almost indistingushable. However, INF_EPS algorithms perform as good as AB.

## MSE of Weighed estimators.

We also want to see how the weighed estimators perform wrt original MAB algorithms and their INF versions. We use two weighed estimators.

* ipw - Inverse propensity weighing
* aipw - Augmented inverse propensity weighing

These are not new MAB algorithms. The are only estimators to calculate mean of already existing algorithm. The main reason to use these estimators is for their unbiasedness properties. Theoretically, IPW is unbiased but had high variance and AIPW is unbiased and has lower variance.

In order to use IPW and AIPW, we need to know the propensity of choosing an arm at every allocation. Propensity of every arm at every time period can be calculated for Thompson Sampling using Monte Carlo simulations but it cannot be calculated for UCB. So we only use weighed estimators for TS.


```{r echo=FALSE, warning=FALSE}


dt <- total_mse %>% filter(alg %in% est_algs)


plot_mse <- ggplot(dt,aes(x=x, y=mn_mse)) +
  geom_line(aes(color=alg)) +
  geom_ribbon(aes(ymin=mn_mse-(1.96*se_mse), ymax=mn_mse+(1.96*se_mse),
                  group=alg), alpha=0.4,  fill="grey70") +
  labs(title = "MSE of Mean") +  xlim(0,xlimit) +
  geom_dl(aes(label=alg), method=list('last.points', cex=0.8)) +
  theme_bw()

plot_mse

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,10)

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,1.5)

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,0.2)


```

MSE of weighed estimators is very high at the start owing to lower propensity of arm selctions increasing the variance of estimate. This slowly goes down as we gather more data (horizon increase).

Also, the MSE of weighed estimators seems to be *higher* than the non-weighed counterparts. This is interesting.

The main property of these algorithms is that their estimators are unbiased (in expectation). But, for one single iteration, the MSE seems to be worse than un-weighed counterpart.


### Compare MSE of Weighed estimators with UCB_INF_EPS.

We also want to see how the weighed estimators perform wrt original MAB algorithms and their INF versions.


```{r echo=FALSE, warning=FALSE}

compare_est_algs = c("ucb_inf_eps", est_algs)

dt <- total_mse %>% filter(alg %in% compare_est_algs)


plot_mse <- ggplot(dt,aes(x=x, y=mn_mse)) +
  geom_line(aes(color=alg)) +
  geom_ribbon(aes(ymin=mn_mse-(1.96*se_mse), ymax=mn_mse+(1.96*se_mse),
                  group=alg), alpha=0.4,  fill="grey70") +
  labs(title = "MSE of Mean") +  xlim(0,xlimit) +
  geom_dl(aes(label=alg), method=list('last.points', cex=0.8)) +
  theme_bw()

plot_mse

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,5)

plot_mse + labs(title = "MSE of Mean Zoomed") +    ylim(0,0.5)


```

UCB_INF_EPS, THOMP_INF_EPS performs better than even Weighed algorithms.



# Small sample properties of algortihms


## Best arm bias

```{r echo=FALSE, warning=FALSE}

# calculate bias

# Best arm of only AB and UCB

means <- group_outcome  %>% group_by(group, alg, ite) %>% summarise(mn = mean(outcome)) %>% ungroup()

weighed_means <- prop_mse %>% group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()


all_means <- rbind(means, weighed_means)

best <- all_means %>% filter(group==which.max(true_means)-1) %>% 
  mutate(bias = mn-max(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), se = sd(bias)/sqrt(n()))

ylimit <- max(abs(c(best$Bias + qnorm(0.975)*best$se, best$Bias - qnorm(0.975)*best$se)))
ylimit <- 1.5*ylimit

ggplot(best, aes(x=reorder(alg, abs(Bias)), y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*se, ymax=Bias+qnorm(0.975)*se), width=0.2) +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of best arm") + theme(axis.text.x = element_text(angle = 90)) 

```

Weighed estimators have the highest bias, even for the best arm. 
This might be because of their high variance properties. As we only have 20 iterations, the bias might not be still converging to 0.

Although, looking at the relative values, might be deceiving. As the highest value of bias in 0.017, which is 0.3% of the actual value.


## Worst arm bias

```{r echo=FALSE, warning=FALSE}
# Worst arm of only AB and UCB

worst <- all_means %>% filter(group==which.min(true_means)-1) %>% 
  mutate(bias = mn-min(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), se = sd(bias)/sqrt(n()))

ylimit <- max(abs(c(worst$Bias + qnorm(0.975)*worst$se, worst$Bias - qnorm(0.975)*worst$se)))
ylimit <- 1.5*ylimit

ggplot(worst, aes(x=reorder(alg, abs(Bias)), y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*se, ymax=Bias+qnorm(0.975)*se), width=0.2) +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of Worst arm") + theme(axis.text.x = element_text(angle = 90)) 

```


```{r echo=FALSE, warning=FALSE}


means <- group_outcome %>% filter(x<100)  %>% group_by(group, alg, ite) %>% summarise(mn = mean(outcome)) %>% ungroup()

weighed_means <- prop_mse %>% filter(x<100) %>% group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()


all_means <- rbind(means, weighed_means)

worst <- all_means %>% filter(group==which.min(true_means)-1) %>% 
  mutate(bias = mn-min(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), se = sd(bias)/sqrt(n()))

ylimit <- max(abs(c(worst$Bias + qnorm(0.975)*worst$se, worst$Bias - qnorm(0.975)*worst$se)))
ylimit <- 1.5*ylimit

ggplot(worst, aes(x=reorder(alg, abs(Bias)), y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*se, ymax=Bias+qnorm(0.975)*se), width=0.2) +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of Worst arm 100") + theme(axis.text.x = element_text(angle = 90)) 

```


```{r echo=FALSE, warning=FALSE}


means <- group_outcome %>% filter(x<200)  %>% group_by(group, alg, ite) %>% summarise(mn = mean(outcome)) %>% ungroup()

weighed_means <- prop_mse %>% filter(x<200) %>% group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()


all_means <- rbind(means, weighed_means)

worst <- all_means %>% filter(group==which.min(true_means)-1) %>% 
  mutate(bias = mn-min(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), se = sd(bias)/sqrt(n()))

ylimit <- max(abs(c(worst$Bias + qnorm(0.975)*worst$se, worst$Bias - qnorm(0.975)*worst$se)))
ylimit <- 1.5*ylimit

ggplot(worst, aes(x=reorder(alg, abs(Bias)), y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*se, ymax=Bias+qnorm(0.975)*se), width=0.2) +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of Worst arm 200") + theme(axis.text.x = element_text(angle = 90)) 

```


```{r echo=FALSE, warning=FALSE}


means <- group_outcome %>% filter(x<300)  %>% group_by(group, alg, ite) %>% summarise(mn = mean(outcome)) %>% ungroup()

weighed_means <- prop_mse %>% filter(x<300) %>% group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()


all_means <- rbind(means, weighed_means)

worst <- all_means %>% filter(group==which.min(true_means)-1) %>% 
  mutate(bias = mn-min(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), se = sd(bias)/sqrt(n()))

ylimit <- max(abs(c(worst$Bias + qnorm(0.975)*worst$se, worst$Bias - qnorm(0.975)*worst$se)))
ylimit <- 1.5*ylimit

ggplot(worst, aes(x=reorder(alg, abs(Bias)), y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*se, ymax=Bias+qnorm(0.975)*se), width=0.2) +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of Worst arm 300") + theme(axis.text.x = element_text(angle = 90)) 

```


```{r echo=FALSE, warning=FALSE}


means <- group_outcome %>% filter(x<400)  %>% group_by(group, alg, ite) %>% summarise(mn = mean(outcome)) %>% ungroup()

weighed_means <- prop_mse %>% filter(x<400) %>% group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()


all_means <- rbind(means, weighed_means)

worst <- all_means %>% filter(group==which.min(true_means)-1) %>% 
  mutate(bias = mn-min(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), se = sd(bias)/sqrt(n()))

ylimit <- max(abs(c(worst$Bias + qnorm(0.975)*worst$se, worst$Bias - qnorm(0.975)*worst$se)))
ylimit <- 1.5*ylimit

ggplot(worst, aes(x=reorder(alg, abs(Bias)), y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*se, ymax=Bias+qnorm(0.975)*se), width=0.2) +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of Worst arm 400") + theme(axis.text.x = element_text(angle = 90)) 

```


The relative value of bias is high for the worst arm.

*One thing to note is that, for thompson sampling based algorithms, we have to choose priors and update posteriors based on rewards, This is problem for worst arm. If we choose bad priors and they barely get allocations, then Bias and MSE will be high, even after using weighed estimators*

This makes thompson sampling even with weighed estimators, undesirable for practical use of inference.

However, for INF_EPS based algorithms, this seem to correct with time as more allocations come from Inference allocations.



## MSE of Best arm 

```{r echo=FALSE, warning=FALSE}

best <- all_means %>%  filter(group==which.max(true_means)-1)  %>% group_by(alg) %>%
  summarise(m=mean(mn), v=var(mn)) %>% mutate(mse=(m-max(true_means))^2+v)


ylimit <- max(best$mse)
ylimit <- 1.5*ylimit

ggplot(best, aes(x=reorder(alg, mse), y=mse)) + geom_bar(stat="identity") +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "MSE of best arm") + theme(axis.title.x=element_blank()) + theme(axis.text.x = element_text(angle = 90)) 


```

MSE is very very low for all algoritms in terms of scale, the only high values seem to be for weighed estimators.

## MSE of Worst arm 


```{r echo=FALSE, warning=FALSE}


worst <- all_means %>%  filter(group==which.min(true_means)-1)  %>% group_by(alg) %>%
  summarise(m=mean(mn), v=var(mn)) %>% mutate(mse=(m-min(true_means))^2)

ylimit <- max(worst$mse)
ylimit <- 1.5*ylimit

ggplot(worst, aes(x=reorder(alg, mse), y=mse)) + geom_bar(stat="identity") +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "MSE of Worst arm") + theme(axis.title.x=element_blank()) + theme(axis.text.x = element_text(angle = 90)) 

```

Again, for vanilla MAB algorithms and their weighes estimators, MSE is high. This seem to reduce for INF_EPS algorithms.

```{r echo=FALSE, warning=FALSE}
dat = worst %>% filter(alg  %in% c('ab', 'eps_greedy', 'ucb_inf_eps', 'thomp_inf_eps_ipw'))

ylimit <- max(dat$mse)
ylimit <- 3*ylimit

ggplot(dat, aes(x=reorder(alg, mse), y=mse)) + geom_bar(stat="identity") +
  theme_bw()  + ylim(-ylimit, ylimit) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "MSE of Worst arm") + theme(axis.title.x=element_blank()) + theme(axis.text.x = element_text(angle = 90)) 

```


# Conclusions

+ UCB_INF_EPS is clear winner for use cases where there is relative importance for both efficiency and Inference. 
+ Weighed Estimators of existing MAB algorithms may have nice properties *in expectation* but for practical purposes when the practitioner has one shot, UCB_INF_EPS will outperform in regret minimization and estimation.
+ This problem is exacerbated if bad priors are chosen for Thompson Sampling based algorithms. 

<!-- ```{r echo=FALSE, warning=FALSE} -->

<!-- transition_main <- group_outcome %>% filter(ite ==0) %>%  group_by(alg, group) %>% mutate(t=row_number()) %>% mutate(mn = cummean(outcome), se = cumvar(outcome)/t) %>%   ungroup() %>% mutate(group = factor(group))  -->

<!-- tran_ucb_inf <- transition_main %>% filter(alg == 'ucb_inf_eps') -->


<!-- p1 <- ggplot(data = tran_ucb_inf, aes(x=group, y=mn)) +  -->
<!--   geom_point(data = tran_ucb_inf, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se))  + -->
<!--   geom_errorbar(data = tran_ucb_inf, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se)) + -->
<!--   theme_bw() + -->
<!--   geom_point(data = true_df, aes(x=grp, y=true_means), color='red') + -->
<!--   ylim(-1,6) + labs(title = 'Mean Estimate of UCB_INF_EPS') -->


<!-- p1 <- p1 + transition_reveal(t) -->


<!-- animate(p1, nframes = 300, fps= 3, width = 800, height = 300, renderer=gifski_renderer(loop = F)) -->

<!-- ``` -->

<!-- ```{r echo=FALSE, warning=FALSE} -->

<!-- tran_ucb <- transition_main %>% filter(alg == 'ucb') -->


<!-- p1 <- ggplot(data = tran_ucb, aes(x=group, y=mn)) +  -->
<!--   geom_point(data = tran_ucb, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se))  + -->
<!--   geom_errorbar(data = tran_ucb, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se)) + -->
<!--   theme_bw() + -->
<!--   geom_point(data = true_df, aes(x=grp, y=true_means), color='red') + -->
<!--   ylim(-1,6)+  labs(title = 'Mean Estimate of UCB') -->


<!-- p1 <- p1 + transition_reveal(t) -->


<!-- animate(p1, nframes = 300, fps= 3, width = 800, height = 300, renderer=gifski_renderer(loop = F)) -->

<!-- ``` -->


<!-- ```{r echo=FALSE, warning=FALSE} -->
<!-- tran_thomp_inf <- transition_main %>% filter(alg == 'thomp_inf_eps') -->


<!-- p1 <- ggplot(data = tran_thomp_inf, aes(x=group, y=mn)) +  -->
<!--   geom_point(data = tran_thomp_inf, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se))  + -->
<!--   geom_errorbar(data = tran_thomp_inf, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se)) + -->
<!--   theme_bw() + -->
<!--   geom_point(data = true_df, aes(x=grp, y=true_means), color='red') + -->
<!--   ylim(-1,6) + labs(title = 'Mean Estimate of THOMP_INF_EPS') -->


<!-- p1 <- p1 + transition_reveal(t) -->


<!-- animate(p1, nframes = 300, fps= 3, width = 800, height = 300, renderer=gifski_renderer(loop = F)) -->

<!-- ``` -->



<!-- ```{r echo=FALSE, warning=FALSE} -->
<!-- tran_thomp <- transition_main %>% filter(alg == 'thomp') -->


<!-- p1 <- ggplot(data = tran_thomp, aes(x=group, y=mn)) +  -->
<!--   geom_point(data = tran_thomp, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se))  + -->
<!--   geom_errorbar(data = tran_thomp, aes(x=group, y=mn, ymax = mn+1.96*se, -->
<!--                                   ymin = mn-1.96*se)) + -->
<!--   theme_bw() + -->
<!--   geom_point(data = true_df, aes(x=grp, y=true_means), color='red') + -->
<!--   ylim(-1,6) + labs(title = 'Mean Estimate of THOMPSON SAMPLING') -->


<!-- p1 <- p1 + transition_reveal(t) -->


<!-- animate(p1, nframes = 300, fps= 3, width = 800, height = 300, renderer=gifski_renderer(loop = F)) -->

<!-- ``` -->


