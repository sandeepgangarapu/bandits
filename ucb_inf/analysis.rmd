```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(directlabels)
```

# Simulation set up

We have 10 arms which have a normal outcome distribution with different means and variances. The values of these true means and variances are given below.

Every time we pull an arm (make an allocation), we sample from the normal distribution of given by the mean and variance of that arm.

We see from the below true values that ARM-8 is the winning arm as it has the highest mean of 4.9



# One big problem with thompson sampling in choosing priors. If we choose bad priors and they barely get allocation, then MSE will be high, even after using weighed estimators.


```{r echo=TRUE}

true_means = c(3.36139279, 2.440392, 4.12747587, 0.25, 4.04024982, 2.8280871, 1.48811249, 0.2334786, 4.953137, 3)

true_vars = c(3.84896514, 3.7338355, 1.88719468, 2.47073726, 4.64474196, 1.97727022, 4.86978148, 2.62207358, 1, 4.06654206)

```





```{r echo=FALSE, cache=TRUE, warning=FALSE}
setwd("G:\\My Drive\\Research\\Bandits\\code\\bandits\\ucb_inf\\Output")

xi_simulation <- FALSE


group_outcome <- read.csv("group_outcome_1.csv") %>% 
  group_by(ite,alg) %>% mutate(x=row_number()) %>%
  ungroup()

regret_mse <- read.csv("regret_1.csv") %>% 
  group_by(ite,alg) %>% mutate(x=row_number()) %>% ungroup()

prop_mse <- read.csv("ipw_aipw_prop.csv") %>% 
  group_by(ite,alg) %>% mutate(x=row_number()) %>% ungroup()


if (xi_simulation) {
  xi_group <- read.csv("group_eps_sim.csv")
  xi_regret <- read.csv("regret_mse_eps_sim.csv")
}



# Setting new WD so that results are saved in different folder
setwd("G:\\My Drive\\Research\\Bandits\\code\\bandits\\ucb_inf\\results")


```

# Group allocation graphs


### We first look at the allocations for widely used algorithms.

```{r echo=FALSE}

df <- group_outcome %>% filter(ite==0) 

df_regret <- regret_mse %>% filter(ite==0)

main_algs <- c("ab", "ucb", "thomp", "eps")

ggplot(df %>% filter(alg == main_algs)) + geom_point(aes(x=x, y=factor(group)), shape=1, alpha=0.6) +
  facet_grid(alg ~.) +
  theme_bw() +
  labs(x='Time Period', y = 'Group') +
  theme(axis.text.y = element_text(size = rel(0.7))) 
# +   ggsave("group_all.png", width = 10, height = 6, dpi=300, units="in")

```

UCB is the most efficient. Looks like Thompson sampling is not as efficient as perceived. In this case, it is hovering between 8, 4, 0


### We first look at the allocations for Inference based algorithms algorithms.

For inference based allocation, we deviate from the main allocation algorithm with the probability of $\epsilon_n$ defined by


$\eta = \frac{\sum{\frac{\sigma^2}{n}}}{\xi K}$
$\epsilon_n = \frac{\eta}{1+\eta}$

$\xi$ and $K$ are user defined parameters that we will discuss later.

The main idea is that by deviating from main algorithm and making inference based allocation, we learn more about an arm. Learning here implies reducing standard error of an arm. This ofcourse comes at the cost of Utility.


```{r echo=FALSE}


adv_algs <- c("ucb", "ucb_inf_eps", "thomp", "thomp_inf_eps")

ggplot(df %>% filter(alg == adv_algs)) + geom_point(aes(x=x, y=factor(group)), shape=1, alpha=0.6) +
  facet_grid(alg ~.) +
  theme_bw() +
  labs(x='Time Period', y = 'Group') +
  theme(axis.text.y = element_text(size = rel(0.7))) 

```


"_inf_eps" suffix suggests that the algorithms makes inference based allocation with some probability. In these algorithms, the allocations are not as concentrated around few arms as those of the main algorithms (UCB, Thompson Sampling).

The relative performance of these algorithms can be formalized in regret analysis.


# Regret Analysis


```{r echo=FALSE}
ggplot(df_regret, aes(x=x, y=regret)) + geom_line(aes(color=alg)) +
  labs(title = "Regret") + xlim(0,7500) +
  geom_dl(aes(label=alg), method='last.points') +
  theme_bw() 
 # geom_text_repel(aes(label=alg)) +
 # ggsave("regret_eps_n.png", width = 10, height = 6, dpi=300, units="in")


```

UCB algorithm is the most efficient. One interesting observation is that ucb_inf_eps performs better than Thompson Sampling. 

This could be because of a bad seed (one random bad simulation). So, we check to see if this the same case for other iterations (other random seeds).


```{r echo=FALSE}



thomp_regret <- regret_mse %>% filter(alg=='thomp') %>% mutate(ite=factor(ite))


ggplot(thomp_regret, aes(x=x, y=regret)) + geom_line(aes(color=ite)) +
  labs(title = "Regret for Different Thompson Sampling Iterations") + xlim(0,7500) +
  geom_dl(aes(label=ite, size=1), method=list('last.points', cex=0.5)) +
  theme_bw()
 # geom_text_repel(aes(label=alg)) +
 # ggsave("regret_eps_n.png", width = 10, height = 6, dpi=300, units="in")

```


There is a huge variance among iterations, however, 0th iteration which was considered in comparison with other algorithms, sits right in the middle, this means we did not get an extreme performing iteration. What we have is reasonable.


# Mean Squared error of mean estimates


```{r echo=FALSE}
df_prop <- prop_mse %>% filter(ite==0) %>% rename(mean_mse = mse) %>% select(-mean_est)
df_mse <- df_regret %>% select(-c(regret, var_mse)) 
mse <- rbind(df_prop, df_mse)


ggplot(mse %>% filter(alg==main_algs),aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) +
  labs(title = "MSE of Mean") 

```

UCB and Thompson Sampling have higher MSE compared to AB or Epsilon Greedy.


```{r echo=FALSE}

less_mse_algs = c("ab", "eps", "ucb_inf_eps", "thomp_inf_eps")

ggplot(mse %>% filter(alg==less_mse_algs),aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) +
  labs(title = "MSE of Mean")

```
The Inference based algorithms are performing much better than Bandit algorithms in terms if MSE and are comparable to traditional algorithms.

Difference between the above algorithms is clear during earlier allocations. So we limit the total allocations to 300 to see these differences.

```{r echo=FALSE}

ggplot(mse%>% filter(x<300 & alg==less_mse_algs), aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) + labs(title = "MSE of Mean Zoomed") + ylim(0, 8) +   geom_dl(aes(label=alg), method=list('last.points', cex=0.5)) + xlim(0, 400) + ylim(0,4)


```
AB, UCB_INF_EPS, THOMP_INF_EPS perform the best and almost indistingushable. However, UCB_INF_EPS is lower compared to others.

## MSE of Weighed estimators.

We also want to see how the weighed estimators perform wrt original MAB algorithms and their INF versions.


```{r echo=FALSE}

weight_algs = c("thomp_ipw", "thomp_aipw", "thomp")

ggplot(mse %>% filter(alg==weight_algs),aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) +
  labs(title = "MSE of Mean")


ggplot(mse%>% filter(x<500 & alg==weight_algs), aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) + labs(title = "MSE of Mean Zoomed") + geom_dl(aes(label=alg), method=list('last.points', cex=0.5)) + xlim(0, 600) + ylim(0,50)

```

MSE of weighed estimators is very high at the start owing to lower propensity of arm selctions increasing the variance os estimate. This slowly goes down as we gather more data (horizon increase)

## Compare MSE of Weighed estimators with UCB_INF_EPS.

We also want to see how the weighed estimators perform wrt original MAB algorithms and their INF versions.


```{r echo=FALSE}

compare_weight_algs = c("thomp_ipw", "thomp_aipw", "ucb_inf_eps", "thomp")

ggplot(mse %>% filter(alg==compare_weight_algs),aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) +
  labs(title = "MSE of Mean")


ggplot(mse%>% filter(x<500 & alg==compare_weight_algs), aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) + labs(title = "MSE of Mean Zoomed") + geom_dl(aes(label=alg), method=list('last.points', cex=0.5)) + xlim(0, 600) + ylim(0,50)


ggplot(mse%>% filter(x<500 & alg==compare_weight_algs), aes(x=x, y=mean_mse)) + geom_line(aes(color=alg)) + labs(title = "MSE of Mean Zoomed") + geom_dl(aes(label=alg), method=list('last.points', cex=0.5)) + xlim(0, 600) + ylim(0,5)


```
UCB_INF_EPS performs better than even Weighed algorithms

# Average number of allocations for each group in each algorithm

## If the horizon is just 2000 allocations

```{r echo=FALSE}

df <- group_outcome %>% filter(x<2000) %>% group_by(alg, group, ite) %>% count() %>% group_by(alg, group) %>% summarise(mean_alloc = mean(n))

ggplot(df, aes(x=alg, y=mean_alloc)) + geom_bar(stat="identity") + facet_wrap(group ~.) + theme(axis.text.x = element_text(angle = 90)) 

```


## If the horizon is 8000 allocations

```{r echo=FALSE}

df <- group_outcome %>% group_by(alg, group, ite) %>% count() %>% group_by(alg, group) %>% summarise(mean_alloc = mean(n))

ggplot(df, aes(x=alg, y=mean_alloc)) + geom_bar(stat="identity") + facet_wrap(group ~.)+ theme(axis.text.x = element_text(angle = 90)) 

```



# results for xi simulation for ucb-inf

$\eta = \frac{\sum{\frac{\sigma^2}{n}}}{\xi K}$
$\epsilon_n = \frac{\eta}{1+\eta}$

## Other possibility of epsilon 
$\epsilon_n = tanh(\eta)$




```{r echo=FALSE, eval=xi_simulation}


xi_group <- xi_group %>% mutate(chi = round(chi,2)) %>%
  group_by(chi) %>% mutate(x=row_number()) %>% ungroup()


ggplot(xi_group) +
  geom_point(aes(x=x, y=factor(group)), shape=1, alpha=0.6) +
  facet_grid(chi ~.) + theme_bw() +
  labs(x='Time Period', y = 'Group') +
  theme(axis.text.y = element_text(size = 6)) + 
  theme(axis.text.y = element_text(size = rel(1))) 

xi_regret <- xi_regret %>% 
  mutate(chi = factor(round(chi,2))) %>% group_by(chi) %>% 
  mutate(x=row_number())

ggplot(xi_regret) + 
  geom_line(aes(x=x, y=regret, color=chi)) + theme_bw()

ggplot(xi_regret %>% filter(x<500)) + 
  geom_line(aes(x=x, y=mean_mse, color=chi))

```


# Small sample properties of algortihms




# best arm bias

```{r echo=FALSE}

# calculate bias

# Best arm of only AB and UCB

means <- group_outcome  %>% group_by(group, alg, ite) %>% summarise(mn = mean(outcome)) %>% ungroup()

# getting thompson group into ipw numbers
prop_mse_normal_thomp <- prop_mse
thomp_group <- group_outcome %>% filter(alg=='thomp') %>% select(group)
thomp_inf_group <- group_outcome %>% filter(alg=='thomp_inf_eps') %>% select(group)

prop_mean_thomp_inf <- prop_mse  %>%
  filter(grepl('inf',alg)) %>% mutate(group = rep(thomp_inf_group$group,2))  %>% select(-c(x, mse)) %>%
  group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()

prop_mean_thomp <- prop_mse %>%
  filter(!grepl('inf',alg)) %>% mutate(group = rep(thomp_group$group,2))  %>%  select(-c(x, mse)) %>%
  group_by(group, alg, ite) %>% summarise(mn = mean(mean_est)) %>% ungroup()


all_means <- rbind(means, prop_mean_thomp_inf, prop_mean_thomp)

best <- all_means %>% filter(group==which.max(true_means)-1) %>% 
  mutate(bias = mn-max(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), sd = sd(bias)/sqrt(n()))


ggplot(best, aes(x=alg, y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*sd, ymax=Bias+qnorm(0.975)*sd), width=0.2) +
  theme_bw()  + ylim(-1, 1) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of best arm") 
 # ggsave("best_bias_2.png", width = 5, height = 5, scale = 0.7, units="in")



```

# Worst arm bias

```{r echo=FALSE}


# Worst arm of only AB and UCB


worst <- group_outcome %>%  filter(group==which.min(true_means)-1)  %>%
  group_by(alg, ite) %>% summarise(mn = mean(outcome)) %>%
  mutate(bias = mn-min(true_means)) %>% group_by(alg) %>%
  summarise(Bias = mean(bias), sd = sd(bias)/sqrt(n()))


ggplot(worst, aes(x=alg, y=Bias)) + geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=Bias-qnorm(0.975)*sd, ymax=Bias+qnorm(0.975)*sd), width=0.2) +
  theme_bw()  + ylim(-1, 1) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "Bias of worst arm") +
  ggsave("worst_bias_2.png", width = 5, height = 5, scale = 0.7, units="in")



```




```{r echo=FALSE}


# mse of best estimate

# Best arm of only AB and UCB
best <- group_outcome %>%  filter(group==which.max(true_means)-1) %>%
  group_by(alg, ite) %>% summarise(mn = mean(outcome)) %>% group_by(alg) %>%
  summarise(m=mean(mn), v=var(mn)) %>% mutate(mse=(m-max(true_means))^2+v)


ggplot(best, aes(x=alg, y=mse)) + geom_bar(stat="identity") +
  theme_bw()  + ylim(-0.01, 0.01) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "MSE of best arm") +
  ggsave("best_mse_2.png", width = 5, height = 5, scale = 0.7, units="in")


# worst arm of only AB and UCB
worst <- group_outcome %>%  filter(group==which.min(true_means)-1) %>%
  group_by(alg, ite) %>% summarise(mn = mean(outcome)) %>% group_by(alg) %>%
  summarise(m=mean(mn), v=var(mn)) %>% mutate(mse=(m-min(true_means))^2+v)


ggplot(worst, aes(x=alg, y=mse)) + geom_bar(stat="identity") +
  theme_bw()  + ylim(-1.5, 1.5) + theme(axis.title.x=element_blank()) +
  geom_hline(yintercept = 0) + labs(title = "MSE of worst arm") +
  ggsave("worst_mse_2.png", width = 5, height = 5, scale = 0.7, units="in")

```





# Normality of worst arm - estimates (mean of worst arm = 0.25)

```{r echo=FALSE}

# estimate normality sim

library(rcompanion)
worst_ab <- group_outcome %>%  filter(group==which.min(true_means)-1 & alg=='ab') %>%
  group_by(ite) %>% summarise(mn = mean(outcome))

plotNormalHistogram(worst_ab$mn, prob = FALSE, col = "gray", main = "Estimates of Worst arm for AB Testing",
                    linecol = "blue", lwd = 2, length = 1000)



worst_ucb <- group_outcome %>%  filter(group==which.min(true_means)-1 & alg=='ucb') %>%
  group_by(ite) %>% summarise(mn = mean(outcome))

plotNormalHistogram(worst_ucb$mn, prob = FALSE, col = "gray", main = "Estimates of Worst arm for UCB",
                    linecol = "blue", lwd = 2, length = 100)




worst_ucb_inf <- group_outcome %>%  filter(group==which.min(true_means)-1 & alg=='ucb_inf_eps') %>%
  group_by(ite) %>% summarise(mn = mean(outcome))

plotNormalHistogram(worst_ucb_inf$mn, prob = FALSE, col = "gray", main = "Estimates of Worst arm for UCB-INF-EPS",
                    linecol = "blue", lwd = 2, length = 100)


shapiro.test(worst_ab$mn)
shapiro.test(worst_ucb$mn)
shapiro.test(worst_ucb_inf$mn)

```


```{r echo=FALSE}

hist_df <- group_outcome %>% filter(alg=='ab') %>%  group_by(ite, group) %>% summarise(mn = mean(outcome))


ggplot(hist_df, aes(x = mn)) +
  geom_histogram(aes(y =..density..), colour = "black", fill = "white") +
  geom_density(aes(y=0.045*..count..), colour="black") +
  facet_wrap(group ~., scales = "free_y")
stat_function(fun = dnorm, args = list(mean = mean(hist_df$mn), sd = sd(hist_df$mn)))


worst_ab <- group_outcome %>%  filter(group==6 & alg=='ab') %>%
  group_by(ite) %>% summarise(mn = mean(outcome))

plotNormalHistogram(worst_ab$mn, prob = FALSE, col = "gray", main = "Estimates of Worst arm for AB Testing",
                    linecol = "blue", lwd = 2, length = 1000)



worst_ucb <- group_outcome %>%  filter(group==6 & alg=='ucb') %>%
  group_by(ite) %>% summarise(mn = mean(outcome))

plotNormalHistogram(worst_ucb$mn, prob = FALSE, col = "gray", main = "Estimates of Worst arm for UCB",
                    linecol = "blue", lwd = 2, length = 100)




worst_ucb_inf <- group_outcome %>%  filter(group==6 & alg=='ucb_inf_eps') %>%
  group_by(ite) %>% summarise(mn = mean(outcome))

plotNormalHistogram(worst_ucb_inf$mn, prob = FALSE, col = "gray", main = "Estimates of Worst arm for UCB-INF-EPS",
                    linecol = "blue", lwd = 2, length = 100)


shapiro.test(worst_ab$mn)
shapiro.test(worst_ucb$mn)
shapiro.test(worst_ucb_inf$mn)
```